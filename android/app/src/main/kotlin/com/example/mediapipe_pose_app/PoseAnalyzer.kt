package com.example.mediapipe_pose_app

import android.annotation.SuppressLint
import android.content.Context
import android.os.Handler
import android.os.Looper
import android.util.Log
import android.util.Size
import androidx.camera.core.*
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.core.content.ContextCompat
import androidx.lifecycle.LifecycleOwner
import com.google.mediapipe.tasks.core.BaseOptions
import com.google.mediapipe.tasks.vision.core.RunningMode
import com.google.mediapipe.tasks.vision.poselandmarker.PoseLandmarker
import com.google.mediapipe.tasks.vision.poselandmarker.PoseLandmarkerResult
import com.google.mediapipe.tasks.vision.poselandmarker.PoseLandmarker.PoseLandmarkerOptions
import com.google.mediapipe.framework.image.MPImage
import io.flutter.plugin.common.MethodChannel
import java.util.concurrent.Executors
import androidx.camera.view.PreviewView


class PoseAnalyzer(
    // Contexto de la aplicaci√≥n, necesario para inicializar el modelo y la c√°mara
    private val context: Context,
    // Canal de comunicaci√≥n con Flutter, para enviar los resultados de la detecci√≥n
    private val channel: MethodChannel,
    // Vista previa de la c√°mara, donde se mostrar√° el video en tiempo real
    private val previewView: PreviewView,

) {
    // Inicializamos PoseLandmarker, que es el modelo de detecci√≥n de poses
    private lateinit var poseLandmarker: PoseLandmarker
    // Executor para manejar el an√°lisis de im√°genes en un hilo separado
    private val cameraExecutor = Executors.newSingleThreadExecutor()

    // Variables para almacenar el tama√±o de la imagen de entrada
    private var inputWidth = 0
    private var inputHeight = 0

    fun setup() {
        try {
            Log.d("PoseAnalyzer", "Inicializando modelo...")

            // Configuraci√≥n de opciones del modelo
            val baseOptions = BaseOptions.builder()
                .setModelAssetPath("pose_landmarker_lite.task")
                .build()

            // Configuraci√≥n de PoseLandmarker
            // Usamos RunningMode.LIVE_STREAM para an√°lisis en tiempo real
            // y configuramos un listener para recibir los resultados
            // que se enviar√°n a Flutter
            // El listener se ejecuta en el hilo principal para evitar problemas de concurrencia
            val options = PoseLandmarkerOptions.builder()
                .setBaseOptions(baseOptions)
                .setRunningMode(RunningMode.LIVE_STREAM)
                .setResultListener { result: PoseLandmarkerResult, _ ->
                    // Extraemos los puntos de referencia de la pose detectada
                    val landmarks = result.landmarks().firstOrNull()
                    // Convertimos los puntos de referencia a un formato que Flutter pueda entender

                    val landmarkData = landmarks?.map { mapOf("x" to it.x(), "y" to it.y()) }

                    val dataToSend = mapOf(
                        "landmarks" to landmarkData,
                        "inputWidth" to inputWidth,
                        "inputHeight" to inputHeight
                    )

                    Handler(Looper.getMainLooper()).post {
                        Log.d("POSE_DEBUG", "‚û°Ô∏è Enviando ${landmarkData?.size ?: 0} puntos con tama√±o $inputWidth x $inputHeight a Flutter")
                        channel.invokeMethod("posePoints", dataToSend)
                    }
                }
                .build()

            // Creamos el PoseLandmarker con las opciones configuradas
            // Usamos createFromOptions para inicializarlo con las opciones
            poseLandmarker = PoseLandmarker.createFromOptions(context, options)

            // Verificamos que el modelo se haya inicializado correctamente
            Log.d("PoseAnalyzer", "Modelo inicializado correctamente.")

            // Iniciamos la c√°mara para comenzar a recibir im√°genes
            startCamera()

            // Enviar tama√±o del preview real a Flutter cuando est√© listo
            previewView.post {
                val width = previewView.width
                val height = previewView.height

                Log.d("POSE_DEBUG", "üìè PreviewView visible: ${width}x$height")

                val previewSize = mapOf("width" to width, "height" to height)
                Handler(Looper.getMainLooper()).post {
                    channel.invokeMethod("onPreviewSize", previewSize)
                }
            }

        } catch (e: Exception) {
            Log.e("PoseAnalyzer", "Error al inicializar el modelo", e)
        }
    }

    @SuppressLint("UnsafeOptInUsageError")
    private fun startCamera() {
        // Obtenemos el ProcessCameraProvider para gestionar la c√°mara
        val cameraProviderFuture = ProcessCameraProvider.getInstance(context)

        // A√±adimos un listener para esperar a que el proveedor de c√°mara est√© listo
        // Usamos ContextCompat.getMainExecutor para asegurarnos de que se ejecute en el hilo principal
        cameraProviderFuture.addListener({
            // Una vez que el proveedor de c√°mara est√° listo, lo obtenemos
            val cameraProvider = cameraProviderFuture.get()

            // Configuramos la vista previa de la c√°mara
            // Usamos Preview.Builder para crear una vista previa
            val preview = Preview.Builder().build().also {
                // Configuramos la vista previa para que use la PreviewView proporcionada
                it.setSurfaceProvider(previewView.surfaceProvider)  // usamos la misma PreviewView
            }

            // Configuramos el an√°lisis de im√°genes
            // Usamos ImageAnalysis.Builder para crear un analizador de im√°genes
            val imageAnalysis = ImageAnalysis.Builder()
                // Configuramos el tama√±o de la resoluci√≥n de destino
                // .setTargetResolution(Size(480, 640))
                // Configuramos el modo de an√°lisis para mantener solo la √∫ltima imagen
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                // Configuramos el an√°lisis para que use un executor espec√≠fico
                .setOutputImageFormat(ImageAnalysis.OUTPUT_IMAGE_FORMAT_YUV_420_888)
                .build()

            // Configuramos el analizador de im√°genes
            // Usamos un lambda para procesar cada ImageProxy que se recibe
            imageAnalysis.setAnalyzer(cameraExecutor) { imageProxy ->
                // Procesamos la imagen recibida
                // Llamamos a processImageProxy para convertir la imagen y pasarla al PoseLandmarker
                processImageProxy(imageProxy)
            }

            // Configuramos el selector de c√°mara para usar la c√°mara frontal
            // Usamos CameraSelector.Builder para crear un selector de c√°mara
            val cameraSelector = CameraSelector.Builder()
                // Especificamos que queremos usar la c√°mara frontal
                .requireLensFacing(CameraSelector.LENS_FACING_FRONT)
                .build()

            // Intentamos vincular la c√°mara al ciclo de vida de la aplicaci√≥n
            // Usamos bindToLifecycle para vincular la c√°mara al ciclo de vida del contexto
            // Esto asegura que la c√°mara se inicie y detenga autom√°ticamente seg√∫n el ciclo de vida de la actividad
            try {
                cameraProvider.unbindAll()
                cameraProvider.bindToLifecycle(
                    context as LifecycleOwner,
                    cameraSelector,
                    preview,
                    imageAnalysis
                )
            } catch (exc: Exception) {
                Log.e("PoseAnalyzer", "Error al iniciar la c√°mara", exc)
            }
        }, ContextCompat.getMainExecutor(context))
    }

    // Variable para almacenar el tiempo del √∫ltimo an√°lisis
    private var lastAnalysisTime = 0L

    // Procesa cada ImageProxy recibido del an√°lisis de im√°genes
    private fun processImageProxy(imageProxy: ImageProxy) {
        // Intentamos obtener la imagen del ImageProxy
        // Si la imagen es nula o el PoseLandmarker no est√° inicializado, cerramos el ImageProxy
        try {
            // Verificamos si el PoseLandmarker est√° inicializado y si la imagen es v√°lida
            val currentTime = System.currentTimeMillis()
            // Si el PoseLandmarker no est√° inicializado, cerramos el ImageProxy
            if (currentTime - lastAnalysisTime < 75) {
                // Si el tiempo desde el √∫ltimo an√°lisis es menor a 75ms, cerramos el ImageProxy
                imageProxy.close() // ‚õî Saltar an√°lisis si fue hace <75ms
                return
            }

            // Verificamos que la imagen no sea nula y que el PoseLandmarker est√© inicializado
            val mediaImage = imageProxy.image
            // Si la imagen es nula, cerramos el ImageProxy y salimos
            if (mediaImage != null && ::poseLandmarker.isInitialized) {
                // Convertimos la imagen a MPImage, que es el formato que MediaPipe usa para procesar im√°genes
                // Obtenemos la rotaci√≥n de la imagen para ajustarla correctamente
                // MediaPipe espera que las im√°genes est√©n en formato NV21, as√≠ que convertimos la imagen
                val rotation = imageProxy.imageInfo.rotationDegrees
                // Convertimos la imagen a MPImage usando MediaPipeImageUtils
                // Esta funci√≥n convierte la imagen YUV a NV21 y luego a un bitmap que MediaPipe puede procesar
                val mpImage: MPImage = MediaPipeImageUtils.imageToMPImage(mediaImage, rotation)
                inputWidth = mpImage.width
                inputHeight = mpImage.height
                // Llamamos al PoseLandmarker para detectar la pose en la imagen
                // Usamos detectAsync para procesar la imagen de forma as√≠ncrona
                // Pasamos la imagen y el timestamp actual para que MediaPipe pueda sincronizar los resultados
                // poseLandmarker.detectAsync(mpImage, System.currentTimeMillis())
                poseLandmarker.detectAsync(mpImage, currentTime)
                // Actualizamos el tiempo del √∫ltimo an√°lisis
                lastAnalysisTime = currentTime
            }
        } catch (e: Exception) {
            Log.e("PoseAnalyzer", "Error procesando imagen", e)
        } finally {
            imageProxy.close()
        }
    }

    fun close() {
        if (::poseLandmarker.isInitialized) {
            poseLandmarker.close()
        }
        cameraExecutor.shutdown()
    }
}